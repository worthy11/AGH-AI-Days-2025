{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3422c30f-062d-4d85-89f3-d5bd6e47fb23",
   "metadata": {},
   "source": [
    "# ✋ **Z punktów do gestów – rozpoznawanie dłoni w akcji!**\n",
    "Cześć! Miło nam powitać Was na naszym workshopie dotyczącym wizji komputerowej, a konkretnie - klasyfikacji gestów. W tym notatniku postaramy się zaimplementować rozwiązanie, które pozwoli w czasie rzeczywistym odgadywać gest pokazywany przez Ciebie do kamery. Jeśli cokolwiek będzie niejasne, nie wahaj się pytać :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a2ad9b-1650-4ede-8f5c-09f8a41107fc",
   "metadata": {},
   "source": [
    "## **0. Zapoznanie z MediaPipe**\n",
    "Czas wykryć pierwsze punkty kluczowe! Uruchom plik `data_collection.py`, a rozpocznie się zczytywanie obrazu z Twojej kamery. Możesz włączyć lub wyłączyć dodatkowe wyświetlanie punktów wciskając 'k', a wyjść przy użyciu 'q'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec941d-d9c4-4efa-af0c-c927d567fe7c",
   "metadata": {},
   "source": [
    "## **1. Dane**\n",
    "Aby rozwiązać nasz problem wykorzystując nadzorowane uczenie maszynowe, naturalnie będziemy potrzebowali zbioru oetykietowanych danych. W tym celu zebraliśmy kilkadziesiąt klatek, na których pokazujemy 5 różnych gestów:\n",
    "- **palm up** ✋\n",
    "- **fist** 👊\n",
    "- **peace** ✌\n",
    "- **thumbs up** 👍\n",
    "- **ok sign** 👌<br/>\n",
    "\n",
    "Aby uzyskać do nich dostęp, wczytaj i wyświetl zawartość plików `data_train.csv` oraz `data_test.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ae5f4d-a7a7-489c-a0f3-e4fc030b7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "url_train = \"data_train.csv\"\n",
    "url_test = \"data_test.csv\"\n",
    "\n",
    "# Załaduj dane treningowe i testowe do dwóch DataFrame'ów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c518c2-3025-4038-b0cf-6cca60bddd87",
   "metadata": {},
   "source": [
    "**Odpowiedz na pytanie**: ile przykładów występuje w każdym ze zbiorów dla poszczególnych gestów?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dddf1a94-6e88-486b-b754-96f6b644f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czy na pewno wszystkie kolumny będą nam potrzebne?\n",
    "# Rozdziel oba DataFrame'y na część danych (X) oraz etykiet (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059c19a-ffe5-4dd1-88d0-7389f4287a2c",
   "metadata": {},
   "source": [
    "**Uwaga**: Kolejną komórkę możesz na razie pominąć. Wrócimy do niej później ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34c54b-f66a-4987-b012-97ff1dacc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miejsce na implementację odpowiednich przekształceń (transformów)\n",
    "def transform1(X):\n",
    "    landmarks = X.reshape(-1, 21, 3).copy()\n",
    "    # ???\n",
    "    return landmarks.reshape(-1, 63)\n",
    "\n",
    "def transform2(X):\n",
    "    landmarks = X.reshape(-1, 21, 3)\n",
    "    # ???\n",
    "    return landmarks.reshape(-1, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5faf55-0e62-44b7-9c2b-df0d596cdf71",
   "metadata": {},
   "source": [
    "## **2. Model**\n",
    "\n",
    "Mając przygotowane dane do naszego zadania, możemy przystąpić do trenowania modelu dokonującego klasyfikacji gestów.\n",
    "\n",
    "Biorąc pod uwagę punkty charaktetystyczne z pojedynczej klatki podczas inferencji, mamy do czynienia z danymi de facto tabelarycznymi, zatem rozsądnym wyborem modelu może być KNN, SVM, Random Forest (bądź inne modele drzewkowe) lub sieć neuronowa MLP.\n",
    "\n",
    "W poniższej komórce znajdują się importy i wstępne ustawienia potrzebne do użycia każdego z wymienionych modeli.\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Wytrenuj każdy z powyższych modeli i zapisz je do osobnych plików pickle, by móc wykorzystać je później w inferencji przy użyciu skryptu Pythonowego. Zwróć uwagę na różnice w dokładności między modelami oraz wpływ różnych wartości hiperparametrów na wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613c5177-fee6-4f4f-ab69-bca0b9902942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5506e97-7039-4f2b-bbd5-f3ffe4716628",
   "metadata": {},
   "source": [
    "### **2.1 K-NearestNeighbors**\n",
    "Na początek spróbujemy zaklasyfikować gesty używając klasyfikatora KNN. Dla klasycznych algorytmów uczenia maszynowego wykorzystamy pakiet `scikit-learn`. Oto dokumentacja: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html <br />\n",
    "\n",
    "Jakie hiperparametry możemy modyfikować? Poeksperymentuj z różnymi wartościami podczas treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fda3590-c9d9-48b2-9bdd-501ef5ec9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "# Miejsce na wytrenowanie modelu i wyświetlenie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbce38-37f3-425b-b1d7-19d8d042365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_path = f'models/knn_model.pkl'\n",
    "# Miejsce na zapisanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9fab8-5c17-4194-9b3d-2e092edf3ddb",
   "metadata": {},
   "source": [
    "### **2.2 Support Vector Machine**\n",
    "Teraz czas na SVM. Oto dokumentacja: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html <br />\n",
    "\n",
    "Jakie hiperparametry możemy modyfikować? Poeksperymentuj z różnymi wartościami podczas treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600716e-37bb-4f5d-8dc2-58d62c58ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "# Miejsce na wytrenowanie modelu  i wyświetlenie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd6a8-1851-4be5-affc-ddee7a28ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_path = f'models/svc_model.pkl'\n",
    "# Miejsce na zapisanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7e286-40e4-4370-8e07-f93552efb188",
   "metadata": {},
   "source": [
    "### **2.3 Random Forest**\n",
    "Teraz wykorzystamy Random Forest. Oto dokumentacja: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html <br />\n",
    "\n",
    "Jakie hiperparametry możemy modyfikować? Poeksperymentuj z różnymi wartościami podczas treningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a94c9-bed2-4980-a26b-8736c043eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "# Miejsce na wytrenowanie modelu i wyświetlenie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f3cc9-bb9f-42ea-9bd6-21b348b9ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_path = f'models/rfc_model.pkl'\n",
    "# Miejsce na zapisanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58086cec-7c6e-4967-9692-9a018affa828",
   "metadata": {},
   "source": [
    "### **2.4 Sieć neuronowa**\n",
    "Czas na sieć neuronową! Tu mamy okazję wykazać się nieco większą kreatywnością. Oto dokumentacja: https://keras.io/guides/sequential_model/ <br />\n",
    "\n",
    "Ile warstw ukrytych powinna mieć sieć? Po ile neuronów powinno się w nich znaleźć? Przez ile epok powinna się uczyć? Poeksperymentuj z różnymi wartościami podczas treningu. Jako metrykę przyjmij `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29a88c9-4db3-4596-b990-b2818de62817",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = keras.models.Sequential()\n",
    "# Miejsce na wytrenowanie modelu i wyświetlenie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7ade7-36fd-4467-a1d7-a4b6dc3d6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save('models/nn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539fcb9-8ebc-478e-8666-0b3087944e69",
   "metadata": {},
   "source": [
    "## **3. Inferencja**\n",
    "Czas przetestować modele w akcji! Uruchom plik `inference.py` w terminalu przy użyciu komendy `py inference.py` lub ulubionym edytorze kodu. Uwaga! Uruchomi się Twoja kamera. Możesz wyłączyć proces wciskając klawisz `q`. Przełączaj się między modelami przy użyciu klawiszy `a` i `d`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
